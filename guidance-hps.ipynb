{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Guidance](https://github.com/guidance-ai/guidance) for JSON-constrained LLM output\n",
    "\n",
    "This notebook demonstrates using Guidance to force JSON format from LLM queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install guidance if needed\n",
    "# !pip install guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import guidance\n",
    "from guidance import system, user, assistant, gen\n",
    "from guidance import json as gen_json\n",
    "from guidance.models import Transformers\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pydantic schema for person extraction\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"Person's name\")\n",
    "    time: str = Field(description=\"Time period when mentioned, or 'not specified'\")\n",
    "    place: str = Field(description=\"Geographic location, or 'not specified'\") \n",
    "    role: str = Field(description=\"Person's role or occupation, or 'not specified'\")\n",
    "\n",
    "class PeopleExtraction(BaseModel):\n",
    "    people: List[Person] = Field(description=\"List of people extracted from text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa0870eb363465789ddccc78c2c7a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gpustat is not installed, run `pip install gpustat` to collect GPU stats.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guidance model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load your model with Guidance\n",
    "model_path = \"/gpfs1/llm/llama-3.2-hf/Meta-Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# Initialize the Guidance model\n",
    "lm = Transformers(model_path, device_map=\"cuda\")\n",
    "print(\"Guidance model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text from your existing data\n",
    "sample_text = \"\"\"Whether Ong would have seen cyberspace as fundamentally oral or literary, he would surely have recognized it as transformative: not just a revitalization of older forms, not just an amplification, but something wholly new. He might have sensed a coming discontinuity akin to the emergence of literacy itself. Few understood better than Ong just how profound a discontinuity that had been.\n",
    "When he began his studies, \"oral literature\" was a common phrase. It is an oxymoron laced with anachronism; the words imply an all-too-unconscious approach to the past by way of the present. Oral literature was generally treated as a variant of writing; this, Ong said, was \"rather like thinking of horses as automobiles without wheels.\"\n",
    "\"Language in fact bears the same relationship to the concept of mind that legislation bears to the concept of parliament,\" says Jonathan Miller: \"it is a competence forever bodying itself in a series of concrete performances.\" Much the same might be said of writing—it is concrete performance—but when the word is instantiated in paper or stone, it takes on a separate existence as artifice. It is a product of tools, and it is a tool. And like many technologies that followed, it thereby inspired immediate detractors.\n",
    "One unlikely Luddite was also one of the first long-term beneficiaries. Plato (channeling the nonwriter Socrates) warned that this technology meant impoverishment.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Function to extract people using Guidance JSON constraints\n",
    "def extract_people_with_guidance(text: str) -> dict:\n",
    "    \"\"\"Extract people information with guaranteed JSON format using Guidance\"\"\"\n",
    "    \n",
    "    # Start with a fresh model instance\n",
    "    model = lm\n",
    "    \n",
    "    with system():\n",
    "        model += \"You are an expert at extracting people information from text.\"\n",
    "    \n",
    "    with user():\n",
    "        model += f\"\"\"Extract all people mentioned in the following text. For each person, provide their name, time period, location, and role. Use 'not specified' for missing information.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Extract people as JSON:\"\"\"\n",
    "    \n",
    "    with assistant():\n",
    "        model += gen_json(name=\"people_data\", schema=PeopleExtraction)\n",
    "    \n",
    "    return model[\"people_data\"]\n",
    "\n",
    "print(\"Function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Guidance-based JSON extraction...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d83319fcc547c4976091cc1db49c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StitchWidget(initial_height='auto', initial_width='100%', srcdoc='<!doctype html>\\n<html lang=\"en\">\\n<head>\\n …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/j/s/jstonge1/.conda/envs/llama_setup/lib/python3.13/site-packages/guidance/models/_transformers.py:522: UserWarning: Cache is too small. Resetting cache (no method implemented to resize cache for type <class 'transformers.cache_utils.DynamicCache'>).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw JSON result:\n",
      "{\"people\": [{\"name\": \"Ong\", \"time\": \"not specified\", \"place\": \"not specified\", \"role\": \"scholar\"}, {\"name\": \"Socrates\", \"time\": \"not specified\", \"place\": \"not specified\", \"role\": \"philosopher\"}, {\"name\": \"Plato\", \"time\": \"not specified\", \"place\": \"not specified\", \"role\": \"philosopher\"}, {\"name\": \"Jonathan Miller\", \"time\": \"not specified\", \"place\": \"not specified\", \"role\": \"scholar\"}]}\n",
      "\n",
      "Parsed and formatted result:\n",
      "{\n",
      "  \"people\": [\n",
      "    {\n",
      "      \"name\": \"Ong\",\n",
      "      \"time\": \"not specified\",\n",
      "      \"place\": \"not specified\",\n",
      "      \"role\": \"scholar\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Socrates\",\n",
      "      \"time\": \"not specified\",\n",
      "      \"place\": \"not specified\",\n",
      "      \"role\": \"philosopher\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Plato\",\n",
      "      \"time\": \"not specified\",\n",
      "      \"place\": \"not specified\",\n",
      "      \"role\": \"philosopher\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Jonathan Miller\",\n",
      "      \"time\": \"not specified\",\n",
      "      \"place\": \"not specified\",\n",
      "      \"role\": \"scholar\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test the extraction\n",
    "print(\"Testing Guidance-based JSON extraction...\")\n",
    "result = extract_people_with_guidance(sample_text)\n",
    "\n",
    "print(\"\\nRaw JSON result:\")\n",
    "print(result)\n",
    "\n",
    "print(\"\\nParsed and formatted result:\")\n",
    "parsed_result = json.loads(result)\n",
    "print(json.dumps(parsed_result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating with Pydantic...\n",
      "✅ JSON is valid according to schema!\n",
      "\n",
      "Extracted people:\n",
      "1. Ong - scholar (not specified, not specified)\n",
      "2. Socrates - philosopher (not specified, not specified)\n",
      "3. Plato - philosopher (not specified, not specified)\n",
      "4. Jonathan Miller - scholar (not specified, not specified)\n"
     ]
    }
   ],
   "source": [
    "# Validate with Pydantic\n",
    "print(\"Validating with Pydantic...\")\n",
    "try:\n",
    "    validated_result = PeopleExtraction.model_validate_json(result)\n",
    "    print(\"✅ JSON is valid according to schema!\")\n",
    "    \n",
    "    print(\"\\nExtracted people:\")\n",
    "    for i, person in enumerate(validated_result.people, 1):\n",
    "        print(f\"{i}. {person.name} - {person.role} ({person.time}, {person.place})\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
