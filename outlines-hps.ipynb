{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Outlines](https://github.com/dottxt-ai/outlines) for JSON-constrained LLM output\n",
    "\n",
    "This notebook demonstrates using Outlines to guarantee structured JSON from LLM queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install outlines if needed\n",
    "# !pip install outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import outlines\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pydantic schema for person extraction\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"Person's name\")\n",
    "    time: str = Field(description=\"Time period when mentioned, or 'not specified'\")\n",
    "    place: str = Field(description=\"Geographic location, or 'not specified'\") \n",
    "    role: str = Field(description=\"Person's role or occupation, or 'not specified'\")\n",
    "\n",
    "class PeopleExtraction(BaseModel):\n",
    "    people: List[Person] = Field(description=\"List of people extracted from text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'outlines' has no attribute 'from_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m model_path = \u001b[33m\"\u001b[39m\u001b[33m/gpfs1/llm/llama-3.2-hf/Meta-Llama-3.2-3B-Instruct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Initialize the Outlines model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model = outlines.from_transformers(\n\u001b[32m      6\u001b[39m     AutoModelForCausalLM.from_pretrained(model_path, device_map=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      7\u001b[39m     AutoTokenizer.from_pretrained(model_path)\n\u001b[32m      8\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOutlines model loaded successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'outlines' has no attribute 'from_transformers'"
     ]
    }
   ],
   "source": [
    "# Load your model with Outlines\n",
    "model_path = \"/gpfs1/llm/llama-3.2-hf/Meta-Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# Initialize the Outlines model\n",
    "model = outlines.from_transformers(\n",
    "    AutoModelForCausalLM.from_pretrained(model_path, device_map=\"cuda\"),\n",
    "    AutoTokenizer.from_pretrained(model_path)\n",
    ")\n",
    "print(\"Outlines model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text from your existing data\n",
    "sample_text = \"\"\"Whether Ong would have seen cyberspace as fundamentally oral or literary, he would surely have recognized it as transformative: not just a revitalization of older forms, not just an amplification, but something wholly new. He might have sensed a coming discontinuity akin to the emergence of literacy itself. Few understood better than Ong just how profound a discontinuity that had been.\n",
    "When he began his studies, \"oral literature\" was a common phrase. It is an oxymoron laced with anachronism; the words imply an all-too-unconscious approach to the past by way of the present. Oral literature was generally treated as a variant of writing; this, Ong said, was \"rather like thinking of horses as automobiles without wheels.\"\n",
    "\"Language in fact bears the same relationship to the concept of mind that legislation bears to the concept of parliament,\" says Jonathan Miller: \"it is a competence forever bodying itself in a series of concrete performances.\" Much the same might be said of writing—it is concrete performance—but when the word is instantiated in paper or stone, it takes on a separate existence as artifice. It is a product of tools, and it is a tool. And like many technologies that followed, it thereby inspired immediate detractors.\n",
    "One unlikely Luddite was also one of the first long-term beneficiaries. Plato (channeling the nonwriter Socrates) warned that this technology meant impoverishment.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Direct structured generation with Pydantic\n",
    "def extract_people_with_outlines(text: str) -> str:\n",
    "    \"\"\"Extract people information with guaranteed JSON format using Outlines\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"Extract all people mentioned in the following text. For each person, provide their name, time period, location, and role. Use 'not specified' for missing information.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Extract people as JSON:\"\"\"\n",
    "    \n",
    "    # Outlines guarantees the output will match the PeopleExtraction schema\n",
    "    result = model(\n",
    "        prompt,\n",
    "        PeopleExtraction,\n",
    "        max_new_tokens=400\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"Function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Outlines-based JSON extraction...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test the extraction\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTesting Outlines-based JSON extraction...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m result = extract_people_with_outlines(sample_text)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRaw JSON result:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mextract_people_with_outlines\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      5\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mExtract all people mentioned in the following text. For each person, provide their name, time period, location, and role. Use \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnot specified\u001b[39m\u001b[33m'\u001b[39m\u001b[33m for missing information.\u001b[39m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[33mText: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[33mExtract people as JSON:\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Outlines guarantees the output will match the PeopleExtraction schema\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     result = model(\n\u001b[32m     13\u001b[39m         prompt,\n\u001b[32m     14\u001b[39m         PeopleExtraction,\n\u001b[32m     15\u001b[39m         max_new_tokens=\u001b[32m400\u001b[39m\n\u001b[32m     16\u001b[39m     )\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the extraction\n",
    "print(\"Testing Outlines-based JSON extraction...\")\n",
    "result = extract_people_with_outlines(sample_text)\n",
    "\n",
    "print(\"\\nRaw JSON result:\")\n",
    "print(result)\n",
    "\n",
    "print(\"\\nParsed and formatted result:\")\n",
    "parsed_result = json.loads(result)\n",
    "print(json.dumps(parsed_result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating with Pydantic...\n",
      "❌ Validation failed: name 'result' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Validate with Pydantic\n",
    "print(\"Validating with Pydantic...\")\n",
    "try:\n",
    "    validated_result = PeopleExtraction.model_validate_json(result)\n",
    "    print(\"✅ JSON is valid according to schema!\")\n",
    "    \n",
    "    print(\"\\nExtracted people:\")\n",
    "    for i, person in enumerate(validated_result.people, 1):\n",
    "        print(f\"{i}. {person.name} - {person.role} ({person.time}, {person.place})\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Outlines approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Simple sentiment analysis\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m sentiment_result = model(\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAnalyze the sentiment: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mThis book completely changed my understanding of information theory!\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     Literal[\u001b[33m\"\u001b[39m\u001b[33mPositive\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mNegative\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mNeutral\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      8\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSentiment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentiment_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Extract specific data types\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Method 2: Using simple types for quick classification\n",
    "from typing import Literal\n",
    "\n",
    "# Simple sentiment analysis\n",
    "sentiment_result = model(\n",
    "    \"Analyze the sentiment: 'This book completely changed my understanding of information theory!'\",\n",
    "    Literal[\"Positive\", \"Negative\", \"Neutral\"]\n",
    ")\n",
    "print(f\"Sentiment: {sentiment_result}\")\n",
    "\n",
    "# Extract specific data types\n",
    "year_result = model(\n",
    "    \"In what year was Plato born? Answer with just the number.\",\n",
    "    int\n",
    ")\n",
    "print(f\"Year: {year_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'outlines' has no attribute 'Template'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Method 3: Using Template for reusable prompts\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m person_template = outlines.Template.from_string(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33mExtract information about people from this \u001b[39m\u001b[33m{{\u001b[39m\u001b[33m content_type }}:\u001b[39m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[33m{{\u001b[39m\u001b[33m text }}\u001b[39m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[33mReturn a JSON object with a list of people, where each person has:\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m- name: person\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms name\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m- time: time period or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnot specified\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33m- place: location or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnot specified\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m- role: their role or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnot specified\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Generate prompt using template\u001b[39;00m\n\u001b[32m     15\u001b[39m templated_prompt = person_template(\n\u001b[32m     16\u001b[39m     content_type=\u001b[33m\"\u001b[39m\u001b[33macademic text\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     text=sample_text[:\u001b[32m500\u001b[39m] + \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Shorter text for demo\u001b[39;00m\n\u001b[32m     18\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: module 'outlines' has no attribute 'Template'"
     ]
    }
   ],
   "source": [
    "# Method 3: Using Template for reusable prompts\n",
    "person_template = outlines.Template.from_string(\"\"\"\n",
    "Extract information about people from this {{ content_type }}:\n",
    "\n",
    "{{ text }}\n",
    "\n",
    "Return a JSON object with a list of people, where each person has:\n",
    "- name: person's name\n",
    "- time: time period or 'not specified'\n",
    "- place: location or 'not specified'\n",
    "- role: their role or 'not specified'\n",
    "\"\"\")\n",
    "\n",
    "# Generate prompt using template\n",
    "templated_prompt = person_template(\n",
    "    content_type=\"academic text\",\n",
    "    text=sample_text[:500] + \"...\"  # Shorter text for demo\n",
    ")\n",
    "\n",
    "print(\"Generated prompt:\")\n",
    "print(templated_prompt)\n",
    "\n",
    "# Use with structured output\n",
    "template_result = model(\n",
    "    templated_prompt,\n",
    "    PeopleExtraction,\n",
    "    max_new_tokens=300\n",
    ")\n",
    "\n",
    "print(\"\\nTemplate result:\")\n",
    "template_parsed = json.loads(template_result)\n",
    "print(json.dumps(template_parsed, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processing multiple texts...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(texts_to_analyze):\n\u001b[32m     12\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExtract people from this text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     result = model(prompt, PeopleExtraction, max_new_tokens=\u001b[32m200\u001b[39m)\n\u001b[32m     14\u001b[39m     batch_results.append(result)\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mText \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext[:\u001b[32m50\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Method 4: Batch processing multiple texts\n",
    "texts_to_analyze = [\n",
    "    \"Aristotle taught Alexander the Great in ancient Macedonia.\",\n",
    "    \"Marie Curie won Nobel Prizes in both Physics and Chemistry in early 20th century France.\",\n",
    "    \"Shakespeare wrote Hamlet during the Elizabethan era in England.\"\n",
    "]\n",
    "\n",
    "print(\"Batch processing multiple texts...\")\n",
    "\n",
    "batch_results = []\n",
    "for i, text in enumerate(texts_to_analyze):\n",
    "    prompt = f\"Extract people from this text: {text}\"\n",
    "    result = model(prompt, PeopleExtraction, max_new_tokens=200)\n",
    "    batch_results.append(result)\n",
    "    \n",
    "    print(f\"\\nText {i+1}: {text[:50]}...\")\n",
    "    parsed = json.loads(result)\n",
    "    for person in parsed['people']:\n",
    "        print(f\"  - {person['name']} ({person['role']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Time the structured generation\u001b[39;00m\n\u001b[32m      4\u001b[39m start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m timed_result = extract_people_with_outlines(sample_text[:\u001b[32m300\u001b[39m])  \u001b[38;5;66;03m# Shorter for speed\u001b[39;00m\n\u001b[32m      6\u001b[39m end_time = time.time()\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOutlines structured generation took: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mextract_people_with_outlines\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      5\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mExtract all people mentioned in the following text. For each person, provide their name, time period, location, and role. Use \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnot specified\u001b[39m\u001b[33m'\u001b[39m\u001b[33m for missing information.\u001b[39m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[33mText: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[33mExtract people as JSON:\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Outlines guarantees the output will match the PeopleExtraction schema\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     result = model(\n\u001b[32m     13\u001b[39m         prompt,\n\u001b[32m     14\u001b[39m         PeopleExtraction,\n\u001b[32m     15\u001b[39m         max_new_tokens=\u001b[32m400\u001b[39m\n\u001b[32m     16\u001b[39m     )\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Time the structured generation\n",
    "start_time = time.time()\n",
    "timed_result = extract_people_with_outlines(sample_text[:300])  # Shorter for speed\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Outlines structured generation took: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Generated {len(timed_result)} characters of valid JSON\")\n",
    "print(f\"Number of people extracted: {len(json.loads(timed_result)['people'])}\")\n",
    "\n",
    "# Verify it's always valid JSON\n",
    "try:\n",
    "    json.loads(timed_result)\n",
    "    print(\"✅ Output is guaranteed valid JSON!\")\n",
    "except:\n",
    "    print(\"❌ JSON parsing failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
